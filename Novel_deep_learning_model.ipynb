{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Novel deep learning model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8XpQ9fkB3Jmy4WRabKekd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hudaor/leaf-disease-1/blob/main/Novel_deep_learning_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSFXw5qtoEZm"
      },
      "outputs": [],
      "source": [
        "#InceptionV3-RF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FakA1tMioYkF",
        "outputId": "594a9e4b-b469-4e09-f365-e3ad141ce96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRB5-UH7pR7g",
        "outputId": "95b3c91a-7687-4ce8-d4d9-3ac217d29b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.5)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.44.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.24.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (13.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOMqbCTIpTpx",
        "outputId": "d14daa01-76c7-4be0-8bf8-0fcab5a4f0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA1MMrvFph5R",
        "outputId": "6ec562e6-9a2b-4729-ccc7-58c9124c6701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Input, Lambda\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "\n",
        "print(os.listdir(\"images/\"))\n",
        "SIZE= 256 #Resize images\n",
        "#Capture training data and labels into respective lists\n",
        "train_images = []\n",
        "train_labels = [] \n",
        "\n",
        "for directory_path in glob.glob(\"images/train/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    print(label)\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        print(img_path)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "\n",
        "#Convert lists to arrays        \n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "\n",
        "# Capture test/validation data and labels into respective lists\n",
        "\n",
        "test_images = []\n",
        "test_labels = [] \n",
        "for directory_path in glob.glob(\"images/validation/*\"):\n",
        "    fruit_label = directory_path.split(\"\\\\\")[-1]\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        test_images.append(img)\n",
        "        test_labels.append(crop_label)\n",
        "\n",
        "#Convert lists to arrays                \n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "#Encode labels from text to integers.\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels)\n",
        "test_labels_encoded = le.transform(test_labels)\n",
        "le.fit(train_labels)\n",
        "train_labels_encoded = le.transform(train_labels)\n",
        "\n",
        "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
        "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
        "\n",
        "###################################################################\n",
        "# Normalize pixel values to between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#One hot encode y values for neural network. \n",
        "from keras.utils import to_categorical\n",
        "y_train_one_hot = to_categorical(y_train)\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "\n",
        "#############################\n",
        "#Load model wothout classifier/fully connected layers\n",
        "inception = InceptionV3(input_shape=(SIZE, SIZE, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
        "for layer in inception.layers:\n",
        "\tlayer.trainable = False\n",
        "    \n",
        "inception.summary()  #Trainable parameters will be 0\n",
        "\n",
        "\n",
        "#Now, let us use features from convolutional network for RF\n",
        "feature_extractor=inception.predict(x_train)\n",
        "\n",
        "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
        "\n",
        "X_for_RF = features #This is our X input to RF\n",
        "\n",
        "#RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding\n",
        "\n",
        "#Send test data through same feature extractor process\n",
        "X_test_feature = inception.predict(x_test)\n",
        "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
        "\n",
        "#Now predict using the trained RF model. \n",
        "prediction_RF = RF_model.predict(X_test_features)\n",
        "#Inverse le transform to get original label back. \n",
        "prediction_RF = le.inverse_transform(prediction_RF)\n",
        "\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, prediction_RF))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, prediction_RF)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)\n",
        "\n",
        "#Check results on a few select images\n",
        "n=np.random.randint(0, x_test.shape[0])\n",
        "img = x_test[n]\n",
        "plt.imshow(img)\n",
        "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
        "input_img_feature=VGG_model.predict(input_img)\n",
        "input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)\n",
        "prediction_RF = RF_model.predict(input_img_features)[0] \n",
        "prediction_RF = le.inverse_transform([prediction_RF])  #Reverse the label encoder to original name\n",
        "print(\"The prediction for this image is: \", prediction_RF)\n",
        "print(\"The actual label for this image is: \", test_labels[n])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vG0CJjiHp7jX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}